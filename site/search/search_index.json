{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This is the new documentation for VAD, a Javascript package for voice activity detection. VAD lets you prompt your user for microphone permissions and run callbacks on segments of audio with user speech in a few lines of code.</p>"},{"location":"developer-guide/hacking/","title":"Hacking","text":""},{"location":"developer-guide/hacking/#setting-up-a-dev-environment","title":"Setting up a dev environment","text":"<p>After cloning the repository, the following commands will install dependencies for the project and run the automated tests. They should all be run from the top level of the repository.</p> <ol> <li><code>npm install</code> to install dependencies.</li> <li><code>npm run build</code> to build all of the packages.</li> <li><code>npm run test</code> to run the automated tests.</li> </ol>"},{"location":"developer-guide/hacking/#manual-testing","title":"Manual testing","text":"<p>The automated tests are useful, but manual testing is even more important. There is now a site included in the source code that you can add to in order to test your changes. I would like to make this an open \"playground\" for people to put whatever helps them test their changes. You can run the test site by running <code>npm run dev</code>. If you make any changes to <code>vad-web</code>, <code>vad-react</code>, or the source code for the test site, you can wait a few seconds and the test site should refresh in your browser with the changes you made.</p>"},{"location":"developer-guide/hacking/#project-management","title":"Project Management","text":"<p>I set up a Github project for VAD to track work related to the project.</p>"},{"location":"user-guide/algorithm/","title":"Algorithm","text":"<p>The VAD algorithm works as follows:</p> <ol> <li>Sample rate conversion is performed on input audio so that the processed audio has a sample rate of 16000.</li> <li>The converted samples are batched into \"frames\" of size <code>frameSamples</code> samples.</li> <li>The Silero vad model is run on each frame and produces a number between 0 and 1 indicating the probability that the sample contains speech.</li> <li>If the algorithm has not detected speech lately, then it is in a state of <code>not speaking</code>. Once it encounters a frame with speech probability greater than <code>positiveSpeechThreshold</code>, it is changed into a state of <code>speaking</code>. When it encounters <code>redemptionFrames</code> frames with speech probability less than <code>negativeSpeechThreshold</code> without having encountered a frame with speech probability greater than <code>positiveSpeechThreshold</code>, the speech audio segment is considered to have ended and the algorithm returns to a state of <code>not speaking</code>. Frames with speech probability in between <code>negativeSpeechThreshold</code> and <code>positiveSpeechThreshold</code> are effectively ignored.</li> <li>When the algorithm detects the end of a speech audio segment (i.e. goes from the state of <code>speaking</code> to <code>not speaking</code>), it counts the number of frames with speech probability greater than <code>positiveSpeechThreshold</code> in the audio segment. If the count is less than <code>minSpeechFrames</code>, then the audio segment is considered a false positive. Otherwise, <code>preSpeechPadFrames</code> frames are prepended to the audio segment and the segment is made accessible through the higher-level API.</li> </ol>"},{"location":"user-guide/algorithm/#configuration","title":"Configuration","text":"<p>All of the main APIs accept certain common configuration parameters that modify the VAD algorithm.</p> <ul> <li><code>positiveSpeechThreshold: number</code> - determines the threshold over which a probability is considered to indicate the presence of speech.</li> <li><code>negativeSpeechThreshold: number</code> - determines the threshold under which a probability is considered to indicate the absence of speech.</li> <li><code>redemptionFrames: number</code> - number of speech-negative frames to wait before ending a speech segment.</li> <li><code>frameSamples: number</code> - the size of a frame in samples - 1536 by default and probably should not be changed.</li> <li><code>preSpeechPadFrames: number</code> - number of audio frames to prepend to a speech segment.</li> <li><code>minSpeechFrames: number</code> - minimum number of speech-positive frames for a speech segment.</li> </ul>"},{"location":"user-guide/api/","title":"API Reference","text":""},{"location":"user-guide/api/#micvad","title":"MicVAD","text":"<p>The <code>MicVAD</code> API is for recording user audio in the browser and running callbacks on speech segments and related events.</p>"},{"location":"user-guide/api/#support","title":"Support","text":"Package Supported <code>@ricky0123/vad-web</code> Yes <code>@ricky0123/vad-node</code> No <code>@ricky0123/vad-react</code> No, use the useMicVAD hook"},{"location":"user-guide/api/#example","title":"Example","text":"<pre><code>import { MicVAD } from \"@ricky0123/vad-web\"\nconst myvad = await MicVAD.new({\n    onSpeechEnd: (audio) =&gt; {\n        // do something with `audio` (Float32Array of audio samples at sample rate 16000)...\n    },\n})\nmyvad.start()\n</code></pre>"},{"location":"user-guide/api/#options","title":"Options","text":"<p>New instances of <code>MicVAD</code> are created by calling the async static method <code>MicVAD.new(options)</code>. The options object can contain the following fields (all are optional).</p> Option Type Description <code>additionalAudioConstraints</code> constraints to pass to getUserMedia via the <code>audio</code> field <code>onFrameProcessed</code> <code>(probabilities: {isSpeech: float; notSpeech: float}) =&gt; any</code> Callback to run after each frame. <code>onVADMisfire</code> <code>() =&gt; any</code> Callback to run if speech start was detected but <code>onSpeechEnd</code> will not be run because the audio segment is smaller than <code>minSpeechFrames</code> <code>onSpeechStart</code> <code>() =&gt; any</code> Callback to run when speech start is detected <code>onSpeechEnd</code> <code>(audio: Float32Array) =&gt; any</code> Callback to run when speech end is detected. Takes as arg a Float32Array of audio samples between -1 and 1, sample rate 16000. This will not run if the audio segment is smaller than <code>minSpeechFrames</code> <code>positiveSpeechThreshold</code> <code>number</code> see algorithm configuration <code>negativeSpeechThreshold</code> <code>number</code> see algorithm configuration <code>redemptionFrames</code> <code>number</code> see algorithm configuration <code>frameSamples</code> <code>number</code> see algorithm configuration <code>preSpeechPadFrames</code> <code>number</code> see algorithm configuration <code>minSpeechFrames</code> <code>number</code> see algorithm configuration"},{"location":"user-guide/api/#attributes","title":"Attributes","text":"Attributes Type Description <code>listening</code> <code>boolean</code> Is the VAD listening to mic input or is it paused? <code>pause</code> <code>() =&gt; void</code> Stop listening to mic input <code>start</code> <code>() =&gt; void</code> Start listening to mic input"},{"location":"user-guide/api/#nonrealtimevad","title":"NonRealTimeVAD","text":"<p>The <code>NonRealTimeVAD</code> API is for identifying segments of user speech if you already have a Float32Array of audio samples.</p>"},{"location":"user-guide/api/#support_1","title":"Support","text":"Package Supported <code>@ricky0123/vad-web</code> Yes <code>@ricky0123/vad-node</code> Yes <code>@ricky0123/vad-react</code> No"},{"location":"user-guide/api/#example_1","title":"Example","text":"<pre><code>const vad = require(\"@ricky0123/vad-node\") // or @ricky0123/vad-web\n\nconst options: Partial&lt;vad.NonRealTimeVADOptions&gt; = { /* ... */ }\nconst myvad = await vad.NonRealTimeVAD.new(options)\nconst audioFileData, nativeSampleRate = ... // get audio and sample rate from file or something\nfor await (const {audio, start, end} of myvad.run(audioFileData, nativeSampleRate)) {\n   // do stuff with\n   //   audio (float32array of audio)\n   //   start (milliseconds into audio where speech starts)\n   //   end (milliseconds into audio where speech ends)\n}\n</code></pre>"},{"location":"user-guide/api/#options_1","title":"Options","text":"<p>New instances of <code>MicVAD</code> are created by calling the async static method <code>MicVAD.new(options)</code>. The options object can contain the following fields (all are optional).</p> Option Type Description <code>positiveSpeechThreshold</code> <code>number</code> see algorithm configuration <code>negativeSpeechThreshold</code> <code>number</code> see algorithm configuration <code>redemptionFrames</code> <code>number</code> see algorithm configuration <code>frameSamples</code> <code>number</code> see algorithm configuration <code>preSpeechPadFrames</code> <code>number</code> see algorithm configuration <code>minSpeechFrames</code> <code>number</code> see algorithm configuration"},{"location":"user-guide/api/#attributes_1","title":"Attributes","text":"Attributes Type Description <code>run</code> <code>async function* (inputAudio: Float32Array, sampleRate: number): AsyncGenerator</code> Run the VAD model on your audio"},{"location":"user-guide/api/#usemicvad","title":"useMicVAD","text":"<p>A React hook wrapper for MicVAD. Use this if you want to run the VAD model on mic input in a React application.</p>"},{"location":"user-guide/api/#support_2","title":"Support","text":"Package Supported <code>@ricky0123/vad-web</code> No, use MicVAD <code>@ricky0123/vad-node</code> No <code>@ricky0123/vad-react</code> Yes"},{"location":"user-guide/api/#example_2","title":"Example","text":"<pre><code>import { useMicVAD } from \"@ricky0123/vad-react\"\n\nconst MyComponent = () =&gt; {\n  const vad = useMicVAD({\n    startOnLoad: true,\n    onSpeechEnd: (audio) =&gt; {\n      console.log(\"User stopped talking\")\n    },\n  })\n  return &lt;div&gt;{vad.userSpeaking &amp;&amp; \"User is speaking\"}&lt;/div&gt;\n}\n</code></pre>"},{"location":"user-guide/api/#options_2","title":"Options","text":"<p>The <code>useMicVAD</code> hook takes an options object with the following fields (all optional).</p> Option Type Description <code>startOnLoad</code> <code>boolean</code> Should the VAD start listening to mic input when it finishes loading? <code>additionalAudioConstraints</code> constraints to pass to getUserMedia via the <code>audio</code> field <code>onFrameProcessed</code> <code>(probabilities: {isSpeech: float; notSpeech: float}) =&gt; any</code> Callback to run after each frame. <code>onVADMisfire</code> <code>() =&gt; any</code> Callback to run if speech start was detected but <code>onSpeechEnd</code> will not be run because the audio segment is smaller than <code>minSpeechFrames</code> <code>onSpeechStart</code> <code>() =&gt; any</code> Callback to run when speech start is detected <code>onSpeechEnd</code> <code>(audio: Float32Array) =&gt; any</code> Callback to run when speech end is detected. Takes as arg a Float32Array of audio samples between -1 and 1, sample rate 16000. This will not run if the audio segment is smaller than <code>minSpeechFrames</code> <code>positiveSpeechThreshold</code> <code>number</code> see algorithm configuration <code>negativeSpeechThreshold</code> <code>number</code> see algorithm configuration <code>redemptionFrames</code> <code>number</code> see algorithm configuration <code>frameSamples</code> <code>number</code> see algorithm configuration <code>preSpeechPadFrames</code> <code>number</code> see algorithm configuration <code>minSpeechFrames</code> <code>number</code> see algorithm configuration"},{"location":"user-guide/api/#returns","title":"Returns","text":"Attributes Type Description <code>listening</code> <code>boolean</code> Is the VAD currently listening to mic input? <code>errored</code> <code>false \\| { message: string; }</code> Did the VAD fail to load? <code>loading</code> <code>boolean</code> Did the VAD finish loading? <code>userSpeaking</code> <code>boolean</code> Is the user speaking? <code>pause</code> <code>() =&gt; void</code> Stop the VAD from running on mic input <code>start</code> <code>() =&gt; void</code> Start running the VAD on mic input"},{"location":"user-guide/browser/","title":"User guide for browser use","text":"<p>The <code>@ricky0123/vad-web</code> package aims to provide an accurate, user-friendly voice activity detector (VAD) that runs in the browser.</p>"},{"location":"user-guide/browser/#script-tags-quick-start","title":"Script tags quick start","text":"<p>The VAD can be used via script tags as follows: <pre><code>&lt;script src=\"https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.js\"&gt;&lt;/script&gt;\n&lt;script src=\"https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.7/dist/bundle.min.js\"&gt;&lt;/script&gt;\n&lt;script&gt;\n  async function main() {\n    const myvad = await vad.MicVAD.new({\n      onSpeechEnd: (audio) =&gt; {\n        // do something with `audio` (Float32Array of audio samples at sample rate 16000)...\n      },\n    })\n    myvad.start()\n  }\n  main()\n&lt;/script&gt;\n</code></pre></p>"},{"location":"user-guide/browser/#bundling","title":"Bundling","text":"<p>To use the VAD in a frontend project managed by a bundler like Webpack, install @ricky0123/vad-web with a command like <pre><code>npm i @ricky0123/vad-web\n</code></pre></p> <p>and use an import like: <pre><code>import { MicVAD } from \"@ricky0123/vad-web\"\nconst myvad = await MicVAD.new({\n  onSpeechEnd: (audio) =&gt; {\n    // do something with `audio` (Float32Array of audio samples at sample rate 16000)...\n  },\n})\nmyvad.start()\n</code></pre></p> <p>You will also need to</p> <ol> <li>serve the <code>silero_vad.onnx</code> file that comes distributed with <code>@ricky0123/vad-web</code></li> <li>serve the <code>vad.worklet.bundle.min.js</code> file that comes distributed with <code>@ricky0123/vad-web</code></li> <li>serve the wasm files that come distributed with the package <code>onnxruntime-web</code></li> </ol> <p>One way to accomplish this is to run a shell script that copies these files into your <code>dist</code> directory (or whatever you have named your output directory) during your build process - see the build script for this website for an example. Or, if you are using Webpack 5, this can be acheived by adding the following to your webpack.config.js (other bundlers may have similar options/plugins): <pre><code>const CopyPlugin = require(\"copy-webpack-plugin\")\n\nmodule.exports = {\n  // ...\n  plugins: [\n    // ...\n    new CopyPlugin({\n      patterns: [\n        // ...\n        {\n          from: \"node_modules/@ricky0123/vad-web/dist/vad.worklet.bundle.min.js\",\n          to: \"[name][ext]\",\n        },\n        {\n          from: \"node_modules/@ricky0123/vad-web/dist/*.onnx\",\n          to: \"[name][ext]\",\n        },\n        { from: \"node_modules/onnxruntime-web/dist/*.wasm\", to: \"[name][ext]\" },\n      ],\n    }),\n  ],\n}\n</code></pre></p> <p>Note that you will need to install <code>copy-webpack-plugin</code> in order for the webpack config snippet above to work (<code>npm i -D copy-webpack-plugin</code> if using npm).</p>"},{"location":"user-guide/browser/#if-you-use-vite-refer-to-the-following-configuration","title":"If you use Vite, refer to the following configuration:","text":"<pre><code>export default defineConfig({\n  plugins: [\n    viteStaticCopy({\n      targets: [\n        {\n          src: 'node_modules/@ricky0123/vad-web/dist/vad.worklet.bundle.min.js',\n          dest: './'\n        },\n        {\n          src: 'node_modules/@ricky0123/vad-web/dist/silero_vad.onnx',\n          dest: './'\n        },\n        {\n          src: 'node_modules/onnxruntime-web/dist/*.wasm',\n          dest: './'\n        }\n      ]\n    })],\n})\n</code></pre> <p>The \"desc\" path is relative to the root directory after build. (Chinese: \"desc\" \u8def\u5f84 \u662f\u76f8\u5bf9\u4e8e build \u540e\u7684\u6839\u76ee\u5f55\u7684\u3002)</p> <p>The \"desc\" path can be adjusted by itself, but you need to configure the modelURL and workletURL when calling the \"MicVad. new()\" method for initialization, which correspond to the \"desc\" path. (Chinese: \u5176\u4e2d\u7684 \u201cdesc\u201d \u8def\u5f84\u53ef\u4ee5\u81ea\u884c\u8c03\u6574\uff0c\u4f46\u9700\u8981\u5728\u8c03\u7528 \"MicVad.new()\" \u65b9\u6cd5\u521d\u59cb\u5316\u65f6\u914d\u7f6e\u597d modelURL\u3001workletURL\uff0c\u4e0e \"desc\" \u8def\u5f84\u76f8\u5bf9\u5e94\u3002)</p>"},{"location":"user-guide/browser/#api","title":"API","text":"<p><code>@ricky0123/vad-web</code> supports the MicVAD and NonRealTimeVAD APIs.</p>"},{"location":"user-guide/node/","title":"User guide for node use","text":"<ol> <li> <p>Install <code>@ricky0123/vad-node</code>:</p> <pre><code>npm i @ricky0123/vad-node\n</code></pre> <p>No other setup is necessary.</p> </li> <li> <p>Example usage:     <pre><code>const vad = require(\"@ricky0123/vad-node\")\n\nconst options: Partial&lt;vad.NonRealTimeVADOptions&gt; = { /* ... */ }\nconst myvad = await vad.NonRealTimeVAD.new(options)\nconst audioFileData, nativeSampleRate = ... // get audio and sample rate from file or something\nfor await (const {audio, start, end} of myvad.run(audioFileData, nativeSampleRate)) {\n    // do stuff with\n    //   audio (float32array of audio)\n    //   start (milliseconds into audio where speech starts)\n    //   end (milliseconds into audio where speech ends)\n}\n</code></pre>     See the docs for NonRealTimeVAD for details. That is the only currently supported API in node.</p> </li> </ol>"},{"location":"user-guide/react/","title":"User guide for use in React projects","text":"<ol> <li> <p>Install <code>@ricky0123/vad-react</code>:</p> <pre><code>npm i @ricky0123/vad-react\n</code></pre> </li> <li> <p>Follow the bundling instructions for <code>@ricky0123/vad-web</code>. To recap, you need to serve the worklet and onnx files that come distributed with <code>@ricky0123/vad-web</code> and the wasm files from <code>onnxruntime-web</code>, which will both be pulled in as dependencies.</p> </li> <li> <p>Use the <code>useMicVAD</code> hook to start the voice activity detector:</p> <p><pre><code>import { useMicVAD } from \"@ricky0123/vad-react\"\n\nconst MyComponent = () =&gt; {\nconst vad = useMicVAD({\n    startOnLoad: true,\n    onSpeechEnd: (audio) =&gt; {\n    console.log(\"User stopped talking\")\n    },\n})\nreturn &lt;div&gt;{vad.userSpeaking &amp;&amp; \"User is speaking\"}&lt;/div&gt;\n}\n</code></pre> See the docs for useMicVAD for details.</p> </li> </ol>"}]}